{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SCALE_FACTOR' from 'config' (c:\\Users\\jotoa\\Documents\\GitHub\\Desafio_Tripulaciones\\Desafio_Tripulaciones\\Reconocimiento_Facial\\config.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7828\\1725701973.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPERSON_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPERSON_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPERSON_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPERSON_4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPERSON_5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPERSON_6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWIDTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSCALE_FACTOR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMIN_NEIGHBORS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'SCALE_FACTOR' from 'config' (c:\\Users\\jotoa\\Documents\\GitHub\\Desafio_Tripulaciones\\Desafio_Tripulaciones\\Reconocimiento_Facial\\config.py)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "\n",
    "from config import PERSON_1, PERSON_2, PERSON_3, PERSON_4, PERSON_5, PERSON_6, WIDTH, SCALE_FACTOR, MIN_NEIGHBORS, PIXEL, NUM_FRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta creada:  ./data/selu2\n"
     ]
    }
   ],
   "source": [
    "#Para capturar rostro en webcam.\n",
    "\n",
    "person_name = input(\"Introduzca su nombre, por favor: \")\n",
    "data_path = './data'\n",
    "person_path = data_path +'/'+ person_name\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(person_path):\n",
    "    print('Carpeta creada: ', person_path)\n",
    "    os.makedirs(person_path)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "face_classif = cv2.CascadeClassifier('frontalface_default.xml')  #cv2.data.haarcascades\n",
    "\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    ret, im = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    im = imutils.resize(im, width=640)\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    aux_frame = im.copy()\n",
    "\n",
    "    faces = face_classif.detectMultiScale(gray, 1.3,5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(im, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "        rostro = aux_frame[y:y+h,x:x+w]\n",
    "        rostro = cv2.resize(rostro,(150,150), interpolation=cv2.INTER_CUBIC)\n",
    "        cv2.imwrite(person_path + '/cara_{}.jpg'.format(count),rostro)\n",
    "        count = count + 1\n",
    "    cv2.imshow('Imagen', im)\n",
    "\n",
    "    k= cv2.waitKey(1)\n",
    "    if k == 27 or count >= 300:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Chequear si la rotación del video está bien:\n",
    "\n",
    "# def check_rotation(path_video_file):\n",
    "#     # this returns meta-data of the video file in form of a dictionary\n",
    "#     meta_dict = ffmpeg.probe(path_video_file)\n",
    "\n",
    "#     # from the dictionary, meta_dict['streams'][0]['tags']['rotate'] is the key\n",
    "#     # we are looking for\n",
    "#     rotateCode = None\n",
    "#     if int(meta_dict['streams'][0]['tags']['rotate']) == 90:\n",
    "#         rotateCode = cv2.ROTATE_90_CLOCKWISE\n",
    "#     elif int(meta_dict['streams'][0]['tags']['rotate']) == 180:\n",
    "#         rotateCode = cv2.ROTATE_180\n",
    "#     elif int(meta_dict['streams'][0]['tags']['rotate']) == 270:\n",
    "#         rotateCode = cv2.ROTATE_90_COUNTERCLOCKWISE\n",
    "\n",
    "#     return rotateCode\n",
    "\n",
    "# #Función para corregir la rotación:\n",
    "\n",
    "# def correct_rotation(im, rotateCode):  \n",
    "#      return cv2.rotate(im, rotateCode) \n",
    "     \n",
    "\n",
    "# # open a pointer to the video file stream\n",
    "# vs = cv2.VideoCapture(video_path)\n",
    "\n",
    "# # check if video requires rotation\n",
    "# rotateCode = check_rotation(video_path)\n",
    "\n",
    "# # loop over frames from the video file stream\n",
    "# while True:\n",
    "#     # grab the frame from the file\n",
    "#     grabbed, frame = vs.read()\n",
    "\n",
    "#     # if frame not grabbed -> end of the video\n",
    "#     if not grabbed:\n",
    "#         break\n",
    "\n",
    "#     # check if the frame needs to be rotated\n",
    "#     if rotateCode is not None:\n",
    "#         frame = correct_rotation(frame, rotateCode)\n",
    "\n",
    "#     # now your logic can start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta creada:  ./data/Fran1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Para capturar rostros desde videos:\n",
    "\n",
    "def generar_frames(PERSON):\n",
    "\n",
    "    '''\n",
    "    Función que recibe la ruta de un video, detecta rostros y captura un numero de frame de dicho rostro,\n",
    "    Como configuración, se puede cambiar, la anchura de la foto, el ajuste del frame del rostro, el numero\n",
    "    de frames detectados para generar una imagen, y el numero de pixeles de la imagenes generadas.\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    person_name = PERSON\n",
    "    data_path = './data'\n",
    "    person_path = data_path +'/'+ person_name\n",
    "\n",
    "    if not os.path.exists(person_path):\n",
    "        print('Carpeta creada: ', person_path)\n",
    "        os.makedirs(person_path)\n",
    "\n",
    "    cap = cv2.VideoCapture(f'videos/{person_name}.mp4')\n",
    "\n",
    "    face_classif = cv2.CascadeClassifier('frontalface_default.xml')  #cv2.data.haarcascades\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, im = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        im = cv2.flip(im,0)\n",
    "        im = imutils.resize(im, width=WIDTH)\n",
    "        gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        aux_frame = im.copy()\n",
    "\n",
    "        faces = face_classif.detectMultiScale(gray, SCALE_FACTOR, MIN_NEIGHBORS)\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(im, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "            rostro = aux_frame[y:y+h,x:x+w]\n",
    "            rostro = cv2.resize(rostro,PIXEL, interpolation=cv2.INTER_CUBIC)\n",
    "            cv2.imwrite(person_path + '/cara_{}.jpg'.format(count),rostro)\n",
    "            count = count + 1\n",
    "        cv2.imshow('Imagen', im)\n",
    "\n",
    "        k= cv2.waitKey(1)\n",
    "        if k == 27 or count >= NUM_FRAMES:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generar_frames(PERSON_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0b33aed511dc55ba970416e862e3e7c40f36ac2e53db324053adfd9531fddb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
